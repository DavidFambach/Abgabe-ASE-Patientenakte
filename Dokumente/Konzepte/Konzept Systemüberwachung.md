# Konzept: Systemüberwachung
Um in einer Microservicearchitektur Fehler und Ineffizienzen im laufenden Betrieb erkennen und einer spezifischen Komponente zuordnen zu können, sind feingranulare Protokolldaten aller Komponenten erforderlich. Auch allgemeine Metriken über Systeme können die Diagnose unterstützen. Diese können dann zum einen zur Untersuchung des Erfüllungsgrades der durch nicht funktionale Anforderung definierten KPIs sowie zur Behandlung von Programmfehlern eingesetzt werden.
Eine Microservicearchitektur hat die Besonderheit, dass Benutzeranfragen in der Regel durch eine Vielzahl von Diensten verarbeitet werden, bevor ein Endergebnis präsentiert werden kann. Jeder einzelne Dienst kann aber Fehler oder Verzögerungen bei der Bearbeitung der Anfrage herbeiführen. Fehler und Verzögerungen entstehen dabei üblicherweise zwar durch einen einzelnen Dienst, werden aber in bestimmten Situationen ausgelöst, die letztendlich von der Benutzeranfrage und vorhergehenden Verarbeitungsschritten abhängig sind. Dementsprechend müssen Protokolldaten einzelner Dienste zur Untersuchung nicht nur vorliegen, sondern auch korrelierbar sein, sodass Verarbeitungsschritte über verschiedene Dienste hinweg einzelnen Benutzeranfragen zugeordnet werden können. Zum einen ist dafür eine einheitliche Protokollierung erforderlich, beispielsweise die Verwendung von Zeitstempeln auf Basis derselben Zeitzone von synchronen Uhren. Zum anderen müssen Protokolleinträge einem Kontext zuordenbar sein. Der OpenTelemetry-Standard bietet ein standardisiertes Format für Protokolldaten, Metriken und Traces. Durch den Einsatz eines zentralen Collectors für OpenTelemetry-Informationen aus allen Komponenten kann eine Korrelation dieser Datenquellen realisiert werden, bevor sie an einen entsprechenden Speicher übergeben werden [1].
Die zu überwachenden Dienste müssen dann lediglich entsprechende OpenTelemetry-Informationen bereitstellen. Das OpenTelemetry-Projekt stellt für verschiedene Programmiersprachen, einschließlich Python, Pakete bereit, die eine einfache Implementierung des Standards ermöglichen [2]. Das Kernmodul ermöglicht dabei die manuelle Erzeugung von Protokolleinträgen sowie Traces und deren Übertragung an den OpenTelemetry-Collector. Für eingesetzte Bibliotheken, beispielsweise den Django-Webserver, existieren außerdem vorgefertigte Pakete, die für typische Ereignisse, beispielsweise die Bearbeitung einer HTTP-GET-Anfrage, automatisch Protokolleinträge und Traces erzeugen und versenden [3]. Auch für das Einsammeln und Bereitstellen allgemeiner Metriken über Systeme existieren bereits Implementierungen, die diese Daten an einen OpenTelemetry-Collector senden [4].
Der OpenTelemetry-Collector gibt die gesammelten und angereicherten Protokolle, Metriken und Traces dann an entsprechende Speicher weiter. Dabei können eingesetzte Speicher beliebig gewählt werden, solange sie das OpenTelemetry-Protokoll und -Format für die jeweiligen Daten unterstützt. Für die Sammlung und weitere Anreicherung von Protokolldaten können FluentBit oder Logstash eingesetzt werden.  Die Speicherung und Indizierung von Protokolldaten kann beispielsweise mit Grafana Loki, Elasticsearch, Splunk, kafka oder Dynatrace realisiert werden. Zur Sammlung von Metriken eignen sich Zeitreihendatenbanken, zum Beispiel Prometheus, InfluxDB, OpenTSDB oder Graphite. Die Visualisierungswerkzeuge unterscheiden sich in den Daten, für die sie geeignet sind, und in den Datenbanken, die sie unterstützen. Zu nennen sind hier Grafana (Protokolle, Metriken und Traces), Jaeger (Traces), Zipkin (Traces) und Kibana (Protokolle und Metriken). Es können auch verschiedene dieser Werkzeuge auf denselben Datenquellen aufbauen.
Es wird keine konkrete Entscheidung für oder gegen konkrete Werkzeuge getroffen, weil die meisten auszuwertenden Anforderungen an diese Werkzeuge nicht feststehen und auch nicht fundiert geschätzt werden können. Unter anderem bieten Cloud-Anbieter bestimmte Lösungen auch im Rahmen eines as-a-Service-Modells an. Die angebotenen Dienste unterscheiden sich dabei massiv zwischen den Cloud-Anbietern. Je nach Einsatzkontext können die beispielhaft ausgewählten Systemüberwachungslösungen durch entsprechende Angebote ersetzt werden. Auch die Frequenz und Größe von anfallenden Daten hängt von Unbekannten ab, sodass zumindest ein Praxistext in einer niedrig skalierten Umgebung erforderlich wäre, um eine verlässliche Vorhersage treffen zu können. Die Bewertung wesentlicher Merkmale der infrage kommenden Werkzeuge zur Verarbeitung von Protokollen, Metriken und Traces, insbesondere Durchsatz, Verarbeitungszeit, Systemanforderungen und Skalierbarkeit, erfordert aber eine solche Vorhersage, damit der Erfüllungsgrad der sich aus der Vorhersage ergebenden Anforderungen gemessen werden kann. Aus diesem Grund wird zwar festgelegt, dass, wie oben beschrieben, Werkzeuge für die Speicherung von Protokollen, Metriken und Traces sowie für deren Visualisierung verwendet werden, aber darauf verzichtet, konkrete Produkte aus diesen Kategorien verbindlich auszuwählen. Aufgrund des Einsatzes des standardisierten OpenTelemetry-Protokolls, können Speicher für Logs, Metriken und Traces ausgetauscht werden, ohne dass dadurch Änderungen in der Anwendung erforderlich werden. Lediglich eventuelle Abhängigkeiten zwischen dem Speicher und dem Visualisierungswerkzeug sind zu berücksichtigen.
Exemplarisch wird als Protokolldatenbank Elasticsearch eingesetzt, die Daten durch einen OpenTelemetry-Collector eingesammelt und angereichert und über die Benutzerschnittstellen von Kibana für Protokolle und Metriken und Jaeger für Traces durchsucht (vgl. Diagramm der logischen Ebene des operationalen Modells).
Dass der Einsatz dieser Technologien im eigenen Programmcode abgesehen von der Einbindung der entsprechenden Pakete kaum Änderungen erfordert, vereinfacht und beschleunigt die Implementierung. Dabei können Fehler und Ineffizienzen nicht nur auf den Dienst, für den sie auftreten, zurückgeführt werden, sondern bis auf den konkreten Abarbeitungsschritt innerhalb des Dienstes. Die Informationen können gesammelt an der Benutzeroberfläche des zentralen Collectors eingesehen werden.

[1]: https://opentelemetry.io/docs/reference/specification/logs/ (Zuletzt abgerufen: 17.11.2022 15:30 Uhr)
[2]: https://opentelemetry.io/docs/instrumentation/python/ (Zuletzt abgerufen: 17.11.2022 15:30 Uhr)
[3]: https://opentelemetry-python.readthedocs.io/en/latest/examples/django/README.html (Zuletzt abgerufen: 17.11.2022 15:30 Uhr)
[4]: https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/receiver/hostmetricsreceiver/README.md (Zuletzt abgerufen: 17.11.2022 15:30 Uhr)
